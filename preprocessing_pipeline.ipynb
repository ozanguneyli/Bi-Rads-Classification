{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1851dfca",
   "metadata": {},
   "source": [
    "# DICOM TO JPEG WITH WINDOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65928f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers import apply_windowing\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_pixels_with_windowing(dcm_file):\n",
    "    im = pydicom.dcmread(dcm_file)\n",
    "    data = im.pixel_array\n",
    "    data = apply_windowing(data, im)\n",
    "    \n",
    "    if im.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    else:\n",
    "        data = data - np.min(data)\n",
    "        \n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_as_jpeg(output_file_path, data):\n",
    "    # Convert the numpy array to a PIL Image\n",
    "    image = Image.fromarray(data)\n",
    "    \n",
    "    # Save the image as JPEG\n",
    "    image.save(output_file_path, format='JPEG')\n",
    "\n",
    "def process_directory(input_dir, output_dir):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.dcm'):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(input_file_path, input_dir)\n",
    "                output_file_path = os.path.join(output_dir, relative_path)\n",
    "                \n",
    "                # Ensure output directory exists\n",
    "                output_file_dir = os.path.dirname(output_file_path)\n",
    "                if not os.path.exists(output_file_dir):\n",
    "                    os.makedirs(output_file_dir)\n",
    "\n",
    "                # Process image\n",
    "                pixels_with_windowing = get_pixels_with_windowing(input_file_path)\n",
    "                \n",
    "                # Save processed image as a JPEG file\n",
    "                output_jpeg_path = output_file_path.replace('.dcm', '.jpeg')\n",
    "                save_as_jpeg(output_jpeg_path, pixels_with_windowing) \n",
    "\n",
    "def main():\n",
    "    input_base_dir = 'demo_dataset'\n",
    "    output_base_dir = 'windowed_dicom'\n",
    "    \n",
    "    input_dir = os.path.join(input_base_dir)\n",
    "    output_dir = os.path.join(output_base_dir)\n",
    "    process_directory(input_dir, output_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ba4a1",
   "metadata": {},
   "source": [
    "# MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mask1(image):\n",
    "    if image is None:\n",
    "        return np.zeros_like(image), np.zeros_like(image)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (1, 1), 0)\n",
    "\n",
    "    # Create a mask using adaptive thresholding\n",
    "    mask = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Apply morphological operations to remove small noises\n",
    "    kernel = np.ones((120,120), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if contours:\n",
    "        # Select the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Create a new mask\n",
    "        new_mask = np.zeros_like(gray)\n",
    "        cv2.drawContours(new_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # Apply the mask\n",
    "        result = cv2.bitwise_and(image, image, mask=new_mask)\n",
    "    else:\n",
    "        new_mask = np.zeros_like(gray)\n",
    "        result = np.zeros_like(image)\n",
    "\n",
    "    return new_mask, result\n",
    "\n",
    "# Second mask creation function\n",
    "def mask2(image):\n",
    "    hh, ww = image.shape[:2]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "    contours = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    if contours:\n",
    "        big_contour = max(contours, key=cv2.contourArea)\n",
    "        mask = np.zeros((hh, ww), dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [big_contour], 0, 255, cv2.FILLED)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25,25))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)\n",
    "        return mask\n",
    "    else:\n",
    "        return np.zeros((hh, ww), dtype=np.uint8)\n",
    "\n",
    "# Main directories\n",
    "input_dataset_path = 'windowed_dicom'\n",
    "test_folder_name = 'val'\n",
    "output_dataset_path = 'processed_dataset'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dataset_path):\n",
    "    os.makedirs(output_dataset_path)\n",
    "\n",
    "# Traverse the input directory and process images\n",
    "for root, dirs, files in os.walk(os.path.join(input_dataset_path)):\n",
    "    for file_name in files:\n",
    "        if file_name.lower().endswith('.jpeg'):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(root, file_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            \n",
    "            # Create Mask1 and Mask2\n",
    "            mask1_mask, mask1_result = mask1(img)\n",
    "            mask2_mask = mask2(img)\n",
    "            \n",
    "            # Combine the two masks and get the result\n",
    "            final_mask = cv2.bitwise_or(mask1_mask, mask2_mask)\n",
    "            final_result = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "\n",
    "            # Create corresponding output path\n",
    "            relative_path = os.path.relpath(root, input_dataset_path)\n",
    "            output_folder = os.path.join(output_dataset_path, relative_path)\n",
    "            \n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "\n",
    "            # Save the final result\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "            cv2.imwrite(output_file_path, final_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c0c1a6",
   "metadata": {},
   "source": [
    "# CROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "class YOLOv5Model:\n",
    "    def __init__(self, model_path):\n",
    "        print(\"Initializing YOLOv5 Model...\")\n",
    "        self.model = torch.hub.load('./', 'custom', path=model_path, source='local')\n",
    "\n",
    "    def detect_and_crop(self, image, image_name, save_path):\n",
    "        try:\n",
    "            # Perform detection using YOLOv5 model\n",
    "            results = self.model(image)\n",
    "\n",
    "            if results.xyxy[0].shape[0] == 0:\n",
    "                # No objects detected, save the original image\n",
    "                destination_path = os.path.join(save_path, image_name)\n",
    "                cv2.imwrite(destination_path, image)\n",
    "                return [destination_path]\n",
    "\n",
    "            cropped_images = []\n",
    "\n",
    "            for idx, det in enumerate(results.xyxy[0]):\n",
    "                xmin, ymin, xmax, ymax = int(det[0]), int(det[1]), int(det[2]), int(det[3])\n",
    "\n",
    "                # Crop the image based on bounding box\n",
    "                cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                # Save cropped image with original image name\n",
    "                cropped_image_path = os.path.join(save_path, image_name)\n",
    "                cv2.imwrite(cropped_image_path, cropped_image)\n",
    "\n",
    "                cropped_images.append(cropped_image_path)\n",
    "\n",
    "            return cropped_images\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during detection and cropping: {e}\")\n",
    "            # Save the original image if an error occurs during cropping\n",
    "            destination_path = os.path.join(save_path, image_name)\n",
    "            cv2.imwrite(destination_path, image)\n",
    "            return [destination_path]\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Script started...\")\n",
    "\n",
    "    # Initialize YOLOv5 model\n",
    "    model_path = \"Breast_Cropper.pt\"  # Replace with your model path\n",
    "    yolo_model = YOLOv5Model(model_path)\n",
    "\n",
    "    # Path to folder containing images to process\n",
    "    image_folder_path = \"processed_dataset\"\n",
    "\n",
    "    # Path to folder where cropped images will be saved\n",
    "    save_folder_path = \"cropped_dataset\"\n",
    "    os.makedirs(save_folder_path, exist_ok=True)\n",
    "\n",
    "    # Get list of images in the folder\n",
    "    image_files = os.listdir(image_folder_path)\n",
    "    image_files = [f for f in image_files if f.endswith('.jpeg') or f.endswith('.png')]  # Filter only JPEG/png images\n",
    "\n",
    "    processed_count = 0\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Full path to the image\n",
    "        image_path = os.path.join(image_folder_path, image_file)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if image is successfully loaded\n",
    "        if image is not None:\n",
    "            # Perform detection and cropping\n",
    "            cropped_images = yolo_model.detect_and_crop(image, image_file, save_folder_path)\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            print(f\"Error: Could not read image at {image_path}\")\n",
    "\n",
    "            # Copy the image to the destination folder as is\n",
    "            destination_path = os.path.join(save_folder_path, image_file)\n",
    "            os.makedirs(save_folder_path, exist_ok=True)\n",
    "            shutil.copy(image_path, destination_path)\n",
    "            processed_count += 1\n",
    "\n",
    "    # Check if the number of processed images matches the total expected\n",
    "    total_images = len(image_files)\n",
    "    if processed_count == total_images:\n",
    "        print(f\"All {total_images} images processed successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Processed {processed_count} out of {total_images} images.\")\n",
    "\n",
    "    print(\"Script completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8736f",
   "metadata": {},
   "source": [
    "# CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4216ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Orijinal ve hedef ana klasör yolları\n",
    "input_root = 'cropped_dataset'  # Orijinal klasör yolu\n",
    "output_root = 'cropped_images_clahe'  # CLAHE uygulanmış görüntülerin kaydedileceği klasör\n",
    "\n",
    "# CLAHE ayarları\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Tüm alt klasörlerdeki görüntüleri dolaşma\n",
    "input_folder = os.path.join(input_root)\n",
    "output_folder = os.path.join(output_root)\n",
    "\n",
    "# Klasör yapısını oluştur\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Her bir klasördeki görüntüleri işle ve kaydet\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(('.jpeg', '.jpg', '.png', '.bmp', '.tiff')):  # İşlenebilir görüntü dosya uzantıları\n",
    "        # Orijinal görüntü dosya yolunu oluştur\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "                \n",
    "        # Görüntüyü yükle\n",
    "        img = cv2.imread(file_path, 0)  # Gri tonlamalı olarak yükleme\n",
    "\n",
    "        # CLAHE uygula\n",
    "        clahe_img = clahe.apply(img)\n",
    "\n",
    "        # Kaydedilecek hedef dosya yolunu oluştur\n",
    "        output_path = os.path.join(output_folder, file)\n",
    "\n",
    "        # CLAHE uygulanmış görüntüyü kaydet\n",
    "        cv2.imwrite(output_path, clahe_img)\n",
    "\n",
    "print(\"Tüm görüntüler CLAHE uygulanarak kaydedildi.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
